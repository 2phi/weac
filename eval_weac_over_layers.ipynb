{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89b0130",
   "metadata": {},
   "source": [
    "# Eval WEAC\n",
    "\n",
    "Initialize models, run over a resolution of 5cm with a standardized weak layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702d9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e07d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from numpy.linalg import LinAlgError\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import tqdm\n",
    "\n",
    "from weac_2.analysis import Analyzer\n",
    "from weac_2.core.system_model import SystemModel\n",
    "from weac_2.components import ModelInput, Segment, ScenarioConfig, WeakLayer, Layer\n",
    "from weac_2.utils.snowpilot_parser import SnowPilotParser, convert_to_mm, convert_to_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4092ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 5 files\n"
     ]
    }
   ],
   "source": [
    "number_of_files = 5\n",
    "\n",
    "# Process multiple files\n",
    "file_paths = []\n",
    "for directory in os.listdir(\"data/snowpits\"):\n",
    "    for file in os.listdir(f\"data/snowpits/{directory}\"):\n",
    "        if file.endswith(\".xml\"):\n",
    "            file_paths.append(f\"data/snowpits/{directory}/{file}\")\n",
    "\n",
    "paths: List[str] = []\n",
    "parsers: List[SnowPilotParser] = []\n",
    "\n",
    "for file_path in file_paths[:number_of_files]:\n",
    "    snowpilot_parser = SnowPilotParser(file_path)\n",
    "    paths.append(file_path)\n",
    "    parsers.append(snowpilot_parser)\n",
    "\n",
    "print(f\"\\nFound {len(paths)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5c086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 50.0, 100.0, 150.0, 200.0, 250.0, 300.0, 350.0, 400.0, 450.0, 500.0, 550.0, 600.0, 650.0, 700.0, 750.0, 800.0, 850.0, 900.0, 950.0, 1000.0, 1050.0, 1100.0, 1150.0, 1200.0, 1250.0, 1300.0, 1350.0, 1400.0, 1450.0, 1500.0, 1550.0, 1600.0, 1650.0, 1700.0, 1750.0, 1800.0, 1850.0, 1900.0, 1950.0, 2000.0, 2050.0, 2100.0, 2150.0, 2200.0, 2250.0, 2300.0, 2350.0, 2400.0, 2450.0, 2500.0, 2550.0, 2600.0, 2650.0, 2700.0, 2750.0, 2800.0, 2850.0, 2900.0, 3000.0, 2950.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pst_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     30\u001b[0m     phi \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     31\u001b[0m         parser\u001b[38;5;241m.\u001b[39msnowpit\u001b[38;5;241m.\u001b[39mcore_info\u001b[38;5;241m.\u001b[39mlocation\u001b[38;5;241m.\u001b[39mslope_angle[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;241m*\u001b[39m convert_to_deg[parser\u001b[38;5;241m.\u001b[39msnowpit\u001b[38;5;241m.\u001b[39mcore_info\u001b[38;5;241m.\u001b[39mlocation\u001b[38;5;241m.\u001b[39mslope_angle[\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     34\u001b[0m _, layers_above \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mextract_weak_layer_and_layers_above(\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msnowpit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepth_top\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m convert_to_mm[parser\u001b[38;5;241m.\u001b[39msnowpit\u001b[38;5;241m.\u001b[39mcore_info\u001b[38;5;241m.\u001b[39mlocation\u001b[38;5;241m.\u001b[39mdepth_top[\u001b[38;5;241m1\u001b[39m]],\n\u001b[1;32m     36\u001b[0m     layers\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Extract layers\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Location' object has no attribute 'depth_top'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 88\u001b[0m\n\u001b[1;32m     68\u001b[0m     data_rows\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     69\u001b[0m         {\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: file_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m         }\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 88\u001b[0m     error_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mpst_id\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m     error_paths[error_id] \u001b[38;5;241m=\u001b[39m file_path\n\u001b[1;32m     90\u001b[0m     error_values[error_id] \u001b[38;5;241m=\u001b[39m e\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pst_id' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Extract data from all PST files\n",
    "error_paths = {}\n",
    "error_values = {}\n",
    "\n",
    "spacing = 50 # mm\n",
    "\n",
    "data_rows = []\n",
    "for i, (file_path, parser) in tqdm.tqdm(\n",
    "    enumerate(zip(paths, parsers)), total=len(paths)\n",
    "):\n",
    "    # setup spacing\n",
    "    height_1 = parser.snowpit.snow_profile.hs[0] * convert_to_mm[parser.snowpit.snow_profile.hs[1]]\n",
    "    height_2 = parser.snowpit.snow_profile.profile_depth[0] * convert_to_mm[parser.snowpit.snow_profile.profile_depth[1]]\n",
    "    if height_1 > height_2:\n",
    "        raise ValueError(\"Height 1 is greater than height 2\")\n",
    "    # space evenly and append the last height\n",
    "    spacing_count = int(height_1 / spacing)\n",
    "    spacing_end = (spacing_count-1) * spacing\n",
    "    spacing_array = np.linspace(0, spacing_end, spacing_count).tolist()\n",
    "    spacing_array = [int(x) for x in spacing_array]\n",
    "    spacing_array.insert(-1, height_1)\n",
    "    print(spacing_array)\n",
    "    exit()\n",
    "    for spacing in spacing_array:\n",
    "        # Extract layers\n",
    "        layers, density_method = parser.extract_layers()\n",
    "    try:\n",
    "        # Extract slope angle\n",
    "        if parser.snowpit.core_info.location.slope_angle is None:\n",
    "            phi = 0.0\n",
    "        else:\n",
    "            phi = (\n",
    "                parser.snowpit.core_info.location.slope_angle[0]\n",
    "                * convert_to_deg[parser.snowpit.core_info.location.slope_angle[1]]\n",
    "            )\n",
    "        _, layers_above = parser.extract_weak_layer_and_layers_above(\n",
    "            parser.snowpit.core_info.location.depth_top[0] * convert_to_mm[parser.snowpit.core_info.location.depth_top[1]],\n",
    "            layers\n",
    "        )\n",
    "\n",
    "        # Extract layers\n",
    "        try:\n",
    "            layers, density_method = parser.extract_layers()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "        cut_length = pst.cut_length[0] * convert_to_mm[pst.cut_length[1]]\n",
    "        column_length = (\n",
    "            pst.column_length[0] * convert_to_mm[pst.column_length[1]]\n",
    "        )\n",
    "        segments = [\n",
    "            Segment(length=cut_length, has_foundation=False, m=0.0),\n",
    "            Segment(\n",
    "                length=column_length - cut_length,\n",
    "                has_foundation=True,\n",
    "                m=0.0,\n",
    "            ),\n",
    "        ]\n",
    "        scenario_config = ScenarioConfig(system_type=\"-vpst\", phi=phi)\n",
    "        model_input = ModelInput(\n",
    "            weak_layer=weak_layer,\n",
    "            layers=layers_above,\n",
    "            scenario_config=scenario_config,\n",
    "            segments=segments,\n",
    "        )\n",
    "        pst_system = SystemModel(model_input=model_input)\n",
    "        pst_analyzer = Analyzer(pst_system)\n",
    "        G, GIc, GIIc = pst_analyzer.differential_ERR(unit=\"J/m^2\")\n",
    "\n",
    "        data_rows.append(\n",
    "            {\n",
    "                \"file_path\": file_path,\n",
    "                \"pst_id\": pst_id,\n",
    "                \"column_length\": column_length,\n",
    "                \"cut_length\": cut_length,\n",
    "                \"phi\": phi,\n",
    "                # Weak Layer properties\n",
    "                \"rho_wl\": weak_layer.rho,\n",
    "                \"E_wl\": weak_layer.E,\n",
    "                \"HH_wl\": weak_layer.hand_hardness,\n",
    "                \"GT_wl\": weak_layer.grain_type,\n",
    "                \"GS_wl\": weak_layer.grain_size,\n",
    "                # Simulation results\n",
    "                \"G\": G,\n",
    "                \"GIc\": GIc,\n",
    "                \"GIIc\": GIIc,\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        error_id = f\"{i}.{pst_id}\"\n",
    "        error_paths[error_id] = file_path\n",
    "        error_values[error_id] = e\n",
    "        overall_excluded_psts += 1\n",
    "\n",
    "dataframe = pd.DataFrame(data_rows)\n",
    "# pprint(error_values)\n",
    "print(f\"\\nFound {len(pst_paths)} files with PST tests\")\n",
    "print(f\"Found {amount_of_psts} PST tests\")\n",
    "print(\"Length of the dataframe: \", len(dataframe))\n",
    "print(f\"Amount of excluded PSTs: {overall_excluded_psts}\")\n",
    "\n",
    "print(f\"\\nFailed to extract layers: {failed_to_extract_layers}\")\n",
    "print(f\"Failed to extract weak layer: {failed_to_extract_weak_layer}\")\n",
    "print(f\"Slope angle is None: {slope_angle_is_None}\")\n",
    "print(f\"Cut length exceeds column length: {cut_length_exceeds_column_length}\")\n",
    "print(\n",
    "    f\"Added Failure Types: {failed_to_extract_layers + slope_angle_is_None + cut_length_exceeds_column_length + failed_to_extract_weak_layer}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
